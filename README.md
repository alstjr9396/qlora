# qLoRA fine tuning study

## ì •ì˜ ğŸ“

ğŸ’¡ Huggingface ëª¨ë¸ì„ qLoRAë¥¼ ì´ìš©í•´ì„œ fine tuning

#### PEFT(Parameter-Efficient Fine-Tuning)
###
    
    - ì—„ì²­ë‚œ ë¹„ìš©ì´ ë“œëŠ” Large pretrained modelì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë“¤ì„ íŒŒì¸íŠœë‹ í•˜ì§€ ì•Šê³  íš¨ê³¼ì ìœ¼ë¡œ í° ëª¨ë¸ì„ ê°œì¡°í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤. PEFT ë©”ì„œë“œëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ ì¤‘ì— ì‘ì€ ì¼ë¶€ë§Œì„ íŒŒì¸íŠœë‹í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ë¹„ìš© ì ˆê° íš¨ê³¼ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.

###

#### LoRA(Low-Rank Adaptation)
###

    - PEFT ë©”ì„œë“œë¡œ large matrixë¥¼ low-rank matricesë¡œ ë¶„í•´í•œë‹¤. ì´ë ‡ê²Œ ê³¼ê°í•˜ê²Œ ì¤„ì¸ íŒŒë¼ë¯¸í„°ë“¤ì€ íŒŒì¸íŠœë‹ì— ì‚¬ìš©ëœë‹¤.

###

#### QLoRA(Quantization + Low-Rank Adaptation)
###

    - LoRA + ì–‘ìí™”

###

<br />


## ì„¤ëª… ğŸ–¥ï¸

#### BitsAndBytesConfig

    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_use_double_quant=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16
    )

    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={"":0})

- `load_in_4bit`: 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ê¸°ë³¸ ëª¨ë¸ì„ ë¡œë“œ
- `bnb_4bit_use_double_quant`: ì–‘ìí™” ìƒìˆ˜ë„ ì–‘ìí™”í•˜ëŠ” ì´ì¤‘ ì–‘ìí™” ì„¤ì •
- `bnb_4bit_quant_type`: nf4(fp4 or nf4)
- `bnb_4bit_compute_dtype`: ê³„ì‚° ë°ì´í„° ìœ í˜•, torch.float32ë³´ë‹¤ torch.bf16ì´ ë¹ ë¥´ë‹¤(ë‚®ì€ ì •ë°€ë„).

#### LoraConfig

    config = LoraConfig(
        r=8,
        lora_alpha=32,
        #target_modules=["query_key_value"],
        target_modules=[
        "q_proj",
        "o_proj",
        "k_proj",
        "v_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM"
    )   

- `peft.prepare_model_for_kbit_training`: ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ì „ì— ì¤€ë¹„ì‹œí‚¤ëŠ” ë©”ì„œë“œ, fp32 í˜•ì‹ìœ¼ë¡œ ë ˆì´ì–´ë¥¼ ì •ê·œí™”í•˜ê³   ì„ë² ë”©ëœ ë ˆì´ì–´ë¥¼ ë§Œë“ ë‹¤. (peft.prepare_model_for_int8_training is deprecated)
- `fp32`: ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë¶€ë™ ì†Œìˆ˜ì  í˜•ì‹
- `r`: í•˜ìœ„ í–‰ë ¬ì˜ ì°¨ì›, LoRA ì–´ëŒ‘í„°ì— 512*64 ë° 64*512 ë§¤ê°œë³€ìˆ˜ê°€ ìˆìŒì„ ì˜ë¯¸
- `lora_alpha`: ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ ë°°ìœ¨ ì¸ì
- `lora_dropout`: LoRA ë ˆì´ì–´ì˜ dropoutí™•ë¥ ë¡œ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.
- `bias`: í¸í–¥ì„ í›ˆë ¨í•  ê²½ìš° all, ì•„ë‹ê²½ìš° none, LoRA í¸í–¥ë§Œ í›ˆë ¨í•˜ë ¤ëŠ” ê²½ìš° lora_only
- `task_type`: ì‚¬ìš©ì¤‘ì¸ ëª¨ë¸ì— ë§ê²Œ ì„¤ì •

#### TrainingArguments

    trainingArgs = transformers.TrainingArguments(
        output_dir=finetunes_model_name,
        bf16=True,
        num_train_epochs=3,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=2,
        gradient_checkpointing=True,
        optim="paged_adamw_8bit",
        logging_steps=5,
        save_strategy="epoch",
        learning_rate=2e-4,
        weight_decay=0.001,
        max_grad_norm=0.3,
        warmup_ratio=0.03,
        group_by_length=False,
        lr_scheduler_type="cosine",
        disable_tqdm=True
    )

- `output_dir`: ëª¨ë¸ ì˜ˆì¸¡ ë° ì²´í¬í¬ì¸íŠ¸ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬
- `num_train_epochs`: ì „ì²´ ë°ì´í„° ì‚¬ìš©(epoch) íšŸìˆ˜
- `per_device_train_batch_size`: GPU ë‹¹ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
- `gradient_accumulation_steps`: Gradient Accumulationì€ ëª¨ë“  ë¯¸ë‹ˆ ë°°ì¹˜ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹  ëˆ„ì ëœ ê¸°ìš¸ê¸°ì— ë”°ë¼ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•œë‹¤. ì´ë–„ ì—…ë°ì´íŠ¸ í•˜ê¸° ì „ ëˆ„ì ë˜ëŠ” ê¸°ìš¸ê¸°ì˜ ê°œìˆ˜
- `gradient_checkpointing`: ì‹¬ì¸µ ì‹ ê²½ë§ì„ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì œí•œëœ ìƒí™©ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ , backward pass ì¤‘ì— intermediate activationsì„ í•œë²ˆì— ëª¨ë‘ ì €ì¥í•˜ì§€ ì•Šê³  ì„ íƒì ìœ¼ë¡œ activationsì„ ë‹¤ì‹œ ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì¸ë‹¤.
- `optim`: ì‚¬ìš©í•  ì˜µí‹°ë§ˆì´ì €
- `logging_steps`: ì½˜ì†” ë¡œê·¸ ì¶œë ¥ step ë‹¨ìœ„
- `save_strategy`: no | epoch | steps
- `weight_decay`: ê°€ì¤‘ì¹˜ ê°ì†ŒëŠ” ì†ì‹¤ í•¨ìˆ˜ì— í˜ë„í‹° í•­ëª©ì„ ì¶”ê°€í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ì‚¬ìš©ë˜ëŠ” ì •ê·œí™” ê¸°ìˆ , ê°€ì¤‘ì¹˜ ê°ì†ŒëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì¤‘ í°ê°’ì— í˜ë„í‹°ë¥¼ ì£¼ëŠ” ì†ì‹¤ í•¨ìˆ˜ì— í•­ëª©ì„ ì¶”ê°€í•˜ì—¬ ì‘ë™í•œë‹¤.(ë‚®ì€ ê°’(1e-8)ë¶€í„° ì‹œì‘í•˜ì—¬ ë‹¨ê³„ì ìœ¼ë¡œ ëŠ˜ë ¤ì•¼í•œë‹¤.)
- `max_grad_norm`: Gradient normì€ ê¸°ìš¸ê¸° ë²¡í„°ì˜ í¬ê¸°ë˜ëŠ” ê¸¸ì´ë¡œ í•¨ìˆ˜ì˜ ë³€í™”ìœ¨ì„ ë‚˜íƒ€ë‚¸ë‹¤. í›ˆë ¨ ì¤‘ ì—…ë°ì´íŠ¸ ë‹¨ê³„ í¬ê¸°ë¥¼ ì œì–´í•˜ëŠ”ë° ë„ì›€ì´ëœë‹¤.
- `warmup_ratio`: warm-up ë¹„ìœ¨ ì„¤ì •, warm-upì€ íŠ¹ì • ìˆ˜ì˜ step í˜¹ì€ epochì— ê±¸ì³ ì´ˆê¸°ê°’ì—ì„œ ì „ì²´ ê°’ê¹Œì§€ í•™ìŠµ ì†ë„ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” í•™ìŠµ ì „ëµì„ ë‚˜íƒ€ë‚¸ë‹¤.
- `lr_scheduler_type`: Learning rate schedulerëŠ” í•™ìŠµì¤‘ì— learning_rateë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¤ëŠ”ë° ì‚¬ìš©ëœë‹¤.

#### Trainer
###

    trainer = transformers.Trainer(
        model=model,
        train_dataset=data["train"],
        args=trainingArgs,
        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),
    )

###

## ì¶œì²˜
- [qlora](https://abvijaykumar.medium.com/fine-tuning-llm-parameter-efficient-fine-tuning-peft-lora-qlora-part-2-d8e23877ac6f)
- [lora](https://huggingface.co/docs/peft/main/en/package_reference/lora)
- [quantization](https://huggingface.co/docs/transformers/main_classes/quantization)
- [peft](https://huggingface.co/docs/peft/main/en/package_reference/peft_model)